{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d78d5e4-8fba-4098-8859-8847149f74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report,accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SpectrogramDataset\n",
    "from config import DATA_PATH, CLASSIFIER_BATCH_SIZE, LEARNING_RATE, SEED, MODELS_PATH, RESULTS_PATH,SAMPLING_RATE,FT_EPOCHS,CHIMPANZEE_DATA_PATH,CLASS_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06db586d-0d9c-4c74-9bfe-26b6c7d07559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectrogram_features(dataset):\n",
    "    \"\"\"\n",
    "    Extract flattened features and labels from SpectrogramDataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : SpectrogramDataset\n",
    "        The spectrogram dataset to extract features from\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (features, labels)\n",
    "        features: numpy array of flattened spectrogram features\n",
    "        labels: numpy array of class labels\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Create a DataLoader to iterate through the dataset\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    for sample, label in dataloader:\n",
    "        # Extract log spectrogram from the sample\n",
    "        spectrogram = sample['data'].squeeze().numpy()\n",
    "        \n",
    "        # Flatten the spectrogram\n",
    "        flattened_features = spectrogram.flatten()\n",
    "        \n",
    "        features.append(flattened_features)\n",
    "        labels.append(label.item())\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "def train_xgboost_on_spectrograms(random_state=42,average='weighted'):\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier on spectrogram features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    random_state : int, optional\n",
    "            Controls the shuffling applied to the data before split\n",
    "    average : str, optional\n",
    "        Method for calculating F1 score (macro, micro, weighted)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (xgb_model, accuracy)\n",
    "        Trained XGBoost model and its accuracy\n",
    "    \"\"\"\n",
    "    # Create SpectrogramDataset\n",
    "    # Load the dataset\n",
    "    train_ds = SpectrogramDataset(f\"{CHIMPANZEE_DATA_PATH}/train\", duration=2, target_sample_rate=SAMPLING_RATE)\n",
    "\n",
    "    test_dataset = SpectrogramDataset(f\"{CHIMPANZEE_DATA_PATH}/val\", duration=2, target_sample_rate=SAMPLING_RATE)\n",
    "\n",
    "    # Def\n",
    "    # dataset = SpectrogramDataset(root_dir)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X_train, y_train = extract_spectrogram_features(train_ds)\n",
    "\n",
    "    X_test, y_test = extract_spectrogram_features(test_dataset)\n",
    "\n",
    "    \n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    # Set XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(train_ds.classes),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "    \n",
    "    # Train the model\n",
    "    model = xgb.train(\n",
    "        params, \n",
    "        dtrain, \n",
    "        num_boost_round=100,\n",
    "        evals=[(dtest, 'eval')],\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    # Predict \n",
    "    y_pred = model.predict(dtest)\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    f1 = f1_score(y_test, predictions, average=average)\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions, \n",
    "                                target_names=train_ds.classes, \n",
    "                                zero_division=0))\n",
    "    \n",
    "    # Print overall results\n",
    "    print(f\"\\nNumber of classes: {len(train_ds.classes)}\")\n",
    "    print(f\"Classes: {train_ds.classes}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{average.capitalize()} F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'classes': train_ds.classes,\n",
    "        'classification_report': classification_report(y_test, predictions, \n",
    "                                                      target_names=train_ds.classes, \n",
    "                                                      zero_division=0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401dfadf-60f8-44cb-9c4c-3328158f5413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/store/cv/users/ybrima/miniconda3/envs/deepc/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:09:45] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:2.30904\n",
      "[1]\teval-mlogloss:2.22433\n",
      "[2]\teval-mlogloss:2.15616\n",
      "[3]\teval-mlogloss:2.08939\n",
      "[4]\teval-mlogloss:2.03467\n",
      "[5]\teval-mlogloss:1.98741\n",
      "[6]\teval-mlogloss:1.93703\n",
      "[7]\teval-mlogloss:1.89461\n",
      "[8]\teval-mlogloss:1.85274\n",
      "[9]\teval-mlogloss:1.81282\n",
      "[10]\teval-mlogloss:1.77516\n",
      "[11]\teval-mlogloss:1.74038\n",
      "[12]\teval-mlogloss:1.70762\n",
      "[13]\teval-mlogloss:1.67722\n",
      "[14]\teval-mlogloss:1.65091\n",
      "[15]\teval-mlogloss:1.62782\n",
      "[16]\teval-mlogloss:1.60563\n",
      "[17]\teval-mlogloss:1.58312\n",
      "[18]\teval-mlogloss:1.56150\n",
      "[19]\teval-mlogloss:1.54241\n",
      "[20]\teval-mlogloss:1.52595\n",
      "[21]\teval-mlogloss:1.50885\n",
      "[22]\teval-mlogloss:1.49514\n",
      "[23]\teval-mlogloss:1.47757\n",
      "[24]\teval-mlogloss:1.46171\n",
      "[25]\teval-mlogloss:1.44613\n",
      "[26]\teval-mlogloss:1.43610\n",
      "[27]\teval-mlogloss:1.42373\n",
      "[28]\teval-mlogloss:1.41060\n",
      "[29]\teval-mlogloss:1.39952\n",
      "[30]\teval-mlogloss:1.38717\n",
      "[31]\teval-mlogloss:1.37797\n",
      "[32]\teval-mlogloss:1.36746\n",
      "[33]\teval-mlogloss:1.35993\n",
      "[34]\teval-mlogloss:1.35252\n",
      "[35]\teval-mlogloss:1.34404\n",
      "[36]\teval-mlogloss:1.33675\n",
      "[37]\teval-mlogloss:1.32887\n",
      "[38]\teval-mlogloss:1.32228\n",
      "[39]\teval-mlogloss:1.31530\n",
      "[40]\teval-mlogloss:1.30703\n",
      "[41]\teval-mlogloss:1.30123\n",
      "[42]\teval-mlogloss:1.29467\n",
      "[43]\teval-mlogloss:1.29039\n",
      "[44]\teval-mlogloss:1.28542\n",
      "[45]\teval-mlogloss:1.28171\n",
      "[46]\teval-mlogloss:1.27466\n",
      "[47]\teval-mlogloss:1.27153\n",
      "[48]\teval-mlogloss:1.26613\n",
      "[49]\teval-mlogloss:1.26228\n",
      "[50]\teval-mlogloss:1.25618\n",
      "[51]\teval-mlogloss:1.25336\n",
      "[52]\teval-mlogloss:1.24951\n",
      "[53]\teval-mlogloss:1.24656\n",
      "[54]\teval-mlogloss:1.24290\n",
      "[55]\teval-mlogloss:1.24021\n",
      "[56]\teval-mlogloss:1.23744\n",
      "[57]\teval-mlogloss:1.23302\n",
      "[58]\teval-mlogloss:1.23058\n",
      "[59]\teval-mlogloss:1.22812\n",
      "[60]\teval-mlogloss:1.22543\n",
      "[61]\teval-mlogloss:1.22227\n",
      "[62]\teval-mlogloss:1.21883\n",
      "[63]\teval-mlogloss:1.21792\n",
      "[64]\teval-mlogloss:1.21579\n",
      "[65]\teval-mlogloss:1.21352\n",
      "[66]\teval-mlogloss:1.21220\n",
      "[67]\teval-mlogloss:1.21063\n",
      "[68]\teval-mlogloss:1.20785\n",
      "[69]\teval-mlogloss:1.20447\n",
      "[70]\teval-mlogloss:1.20351\n",
      "[71]\teval-mlogloss:1.20250\n",
      "[72]\teval-mlogloss:1.19999\n",
      "[73]\teval-mlogloss:1.19987\n",
      "[74]\teval-mlogloss:1.19798\n",
      "[75]\teval-mlogloss:1.19634\n",
      "[76]\teval-mlogloss:1.19463\n",
      "[77]\teval-mlogloss:1.19445\n",
      "[78]\teval-mlogloss:1.19204\n",
      "[79]\teval-mlogloss:1.19050\n",
      "[80]\teval-mlogloss:1.18873\n",
      "[81]\teval-mlogloss:1.18622\n",
      "[82]\teval-mlogloss:1.18553\n",
      "[83]\teval-mlogloss:1.18496\n",
      "[84]\teval-mlogloss:1.18499\n",
      "[85]\teval-mlogloss:1.18435\n",
      "[86]\teval-mlogloss:1.18314\n",
      "[87]\teval-mlogloss:1.18296\n",
      "[88]\teval-mlogloss:1.18275\n",
      "[89]\teval-mlogloss:1.18131\n",
      "[90]\teval-mlogloss:1.18033\n",
      "[91]\teval-mlogloss:1.17967\n",
      "[92]\teval-mlogloss:1.17796\n",
      "[93]\teval-mlogloss:1.17659\n",
      "[94]\teval-mlogloss:1.17604\n",
      "[95]\teval-mlogloss:1.17576\n",
      "[96]\teval-mlogloss:1.17567\n",
      "[97]\teval-mlogloss:1.17604\n",
      "[98]\teval-mlogloss:1.17517\n",
      "[99]\teval-mlogloss:1.17448\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARN       0.67      0.53      0.59        85\n",
      "         CHE       0.80      0.80      0.80        88\n",
      "         CHI       0.68      0.76      0.72        83\n",
      "         FRE       0.55      0.54      0.55        76\n",
      "         GUM       1.00      0.59      0.74        17\n",
      "         LIT       0.68      0.76      0.71       168\n",
      "         LOU       0.92      0.59      0.72        58\n",
      "         NGO       0.85      0.67      0.75        42\n",
      "         ORI       1.00      0.66      0.79        73\n",
      "         PAN       0.38      0.58      0.46       167\n",
      "         THE       0.62      0.33      0.43        73\n",
      "\n",
      "    accuracy                           0.63       930\n",
      "   macro avg       0.74      0.62      0.66       930\n",
      "weighted avg       0.67      0.63      0.64       930\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_weighted \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xgboost_on_spectrograms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m, in \u001b[0;36mtrain_xgboost_on_spectrograms\u001b[0;34m(random_state, average)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, predictions, \n\u001b[1;32m     99\u001b[0m                             target_names\u001b[38;5;241m=\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mclasses, \n\u001b[1;32m    100\u001b[0m                             zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Print overall results\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mclasses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "results_weighted = train_xgboost_on_spectrograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47cc3c3-04f0-48c8-929a-19c61fdbb60c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(results['accuracy'])\n",
    "print(results['f1_score'])\n",
    "print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3abf5e28-fc44-4215-a78c-4954db9f830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_spectrograms(\n",
    "    model, \n",
    "    dataset_path, \n",
    "    val_dataset_path=None, \n",
    "    duration=2, \n",
    "    target_sample_rate=SAMPLING_RATE, \n",
    "    random_state=42, \n",
    "    average='weighted'\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a machine learning classifier on spectrogram features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : ClassifierMixin\n",
    "        A scikit-learn compatible machine learning model\n",
    "    dataset_path : str\n",
    "        Path to the training dataset\n",
    "    val_dataset_path : str, optional\n",
    "        Path to the validation dataset. If None, will use a train-test split\n",
    "    duration : int, optional\n",
    "        Duration of audio clips\n",
    "    target_sample_rate : int, optional\n",
    "        Target sampling rate for audio processing\n",
    "    random_state : int, optional\n",
    "        Controls the shuffling applied to the data before split\n",
    "    average : str, optional\n",
    "        Method for calculating F1 score (macro, micro, weighted)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: A dictionary containing model training results\n",
    "    \"\"\"\n",
    "    # Create SpectrogramDataset for training\n",
    "    train_ds = SpectrogramDataset(dataset_path, duration=duration, target_sample_rate=target_sample_rate)\n",
    "    \n",
    "    # Determine validation dataset\n",
    "    if val_dataset_path:\n",
    "        test_dataset = SpectrogramDataset(val_dataset_path, duration=duration, target_sample_rate=target_sample_rate)\n",
    "        # Extract features for separate datasets\n",
    "        X_train, y_train = extract_spectrogram_features(train_ds)\n",
    "        X_test, y_test = extract_spectrogram_features(test_dataset)\n",
    "    else:\n",
    "\n",
    "        X, y = extract_spectrogram_features(train_ds)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)\n",
    "    \n",
    "    # Special handling for XGBoost if the model is an XGBoost model\n",
    "    if isinstance(model, xgb.XGBClassifier):\n",
    "        # For XGBoost classifier, use its native fit method\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        # For other scikit-learn compatible models\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=average)\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        target_names=train_ds.classes, \n",
    "        zero_division=0\n",
    "    ))\n",
    "    \n",
    "    # Print overall results\n",
    "    print(f\"\\nNumber of classes: {len(train_ds.classes)}\")\n",
    "    print(f\"Classes: {train_ds.classes}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{average.capitalize()} F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'classes': train_ds.classes,\n",
    "        'classification_report': classification_report(\n",
    "            y_test, \n",
    "            y_pred, \n",
    "            target_names=train_ds.classes, \n",
    "            zero_division=0\n",
    "        )\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97d34fe-182c-4520-ada0-d5a18b37a62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARN       0.73      0.45      0.55        85\n",
      "         CHE       0.80      0.80      0.80        88\n",
      "         CHI       0.70      0.77      0.74        83\n",
      "         FRE       0.72      0.50      0.59        76\n",
      "         GUM       1.00      0.59      0.74        17\n",
      "         LIT       0.63      0.76      0.69       168\n",
      "         LOU       0.83      0.59      0.69        58\n",
      "         NGO       0.85      0.67      0.75        42\n",
      "         ORI       0.98      0.66      0.79        73\n",
      "         PAN       0.37      0.61      0.46       167\n",
      "         THE       0.74      0.34      0.47        73\n",
      "\n",
      "    accuracy                           0.63       930\n",
      "   macro avg       0.76      0.61      0.66       930\n",
      "weighted avg       0.69      0.63      0.64       930\n",
      "\n",
      "\n",
      "Number of classes: 11\n",
      "Classes: ['ARN', 'CHE', 'CHI', 'FRE', 'GUM', 'LIT', 'LOU', 'NGO', 'ORI', 'PAN', 'THE']\n",
      "Accuracy: 0.6290\n",
      "Weighted F1 Score: 0.6357\n"
     ]
    }
   ],
   "source": [
    "train_ds = SpectrogramDataset(f\"{CHIMPANZEE_DATA_PATH}/train\", duration=2, target_sample_rate=SAMPLING_RATE)\n",
    "\n",
    "\n",
    "# Random Forest example\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_results = train_model_on_spectrograms(rf_model, f\"{CHIMPANZEE_DATA_PATH}/train\",f\"{CHIMPANZEE_DATA_PATH}/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99da2b-0f34-46c9-8faa-f17f1be5776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['accuracy'])\n",
    "print(results['f1_score'])\n",
    "print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39dc2b-5eb1-4372-ac35-652c92d13d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost example\n",
    "xgb_model = XGBClassifier(\n",
    "        objective='multi:softprob', \n",
    "        num_class=len(train_ds.classes),\n",
    "        max_depth=5, \n",
    "        learning_rate=0.1, \n",
    "        n_estimators=100\n",
    "    )\n",
    "xgb_results = train_model_on_spectrograms(xgb_model, f\"{CHIMPANZEE_DATA_PATH}/train\",f\"{CHIMPANZEE_DATA_PATH}/val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893bbce-c6ac-47db-a35f-cfb0de6eae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['accuracy'])\n",
    "print(results['f1_score'])\n",
    "print(results['classification_report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
